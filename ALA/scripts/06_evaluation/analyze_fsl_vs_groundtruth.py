#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Few-Shot Learning vs Ground Truth ì§ì ‘ ëŒ€ì¡° ë¶„ì„

- FSL ê²°ê³¼ë¥¼ Ground Truthì™€ ì§ì ‘ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ë¶„ì„
- Threshold ì¦ê°€ì— ë”°ë¥¸ ë³´ìˆ˜ì  ì˜ˆì¸¡ ê²½í–¥ ë¶„ì„
- Table 8 Total ê°’ì˜ ê°ì†Œ íŒ¨í„´ í™•ì¸ (ì´ìƒì ì¸ ê²½ìš°)
"""

import os
import json
import pandas as pd
from collections import defaultdict, Counter

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def find_project_root():
    """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
    current_dir = os.getcwd()
    for i in range(4):
        path = os.path.join(current_dir, "data", "test_category")
        if os.path.exists(path):
            return os.path.abspath(current_dir)
        current_dir = os.path.dirname(current_dir)
    raise FileNotFoundError("í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'data/test_category' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

PROJECT_ROOT = find_project_root()
print(f"ğŸ¯ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")

def get_available_experiments():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Few-Shot Learning ì‹¤í—˜ ì¡°í•© ì°¾ê¸°"""
    base_dir = os.path.join(PROJECT_ROOT, "data", "test_category", "7.results", "resnet")
    experiments = []
    if os.path.exists(base_dir):
        for shot_dir in sorted(os.listdir(base_dir)):
            if shot_dir.startswith("shot_"):
                shot = int(shot_dir.split("_")[1])
                shot_path = os.path.join(base_dir, shot_dir)
                for threshold_dir in sorted(os.listdir(shot_path)):
                    if threshold_dir.startswith("threshold_"):
                        threshold = float(threshold_dir.split("_")[1])
                        experiments.append((shot, threshold))
    print(f"ë°œê²¬ëœ ì‹¤í—˜ ì¡°í•©: {len(experiments)}ê°œ")
    return experiments

def get_ground_truth_mapping():
    """Ground Truth ë§¤í•‘ ìƒì„±"""
    gt_dir = os.path.join(PROJECT_ROOT, "data", "test_category", "7.results", "ground_truth")
    gt_mapping = {}
    class_folders = ["Class_0", "Class_1", "Class_2", "Class_3", 
                    "unknown_egifence", "unknown_human", "unknown_none", "unknown_road"]
    
    gt_stats = Counter()
    for class_folder in class_folders:
        class_path = os.path.join(gt_dir, class_folder)
        if os.path.exists(class_path):
            for filename in os.listdir(class_path):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    gt_mapping[filename] = class_folder
                    gt_stats[class_folder] += 1
    
    print("Ground Truth í†µê³„:")
    for class_name, count in sorted(gt_stats.items()):
        print(f"  {class_name}: {count}ê°œ")
    
    return gt_mapping

def get_fsl_predictions(shot, threshold):
    """FSL ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ"""
    base_dir = os.path.join(PROJECT_ROOT, "data", "test_category", "7.results", "resnet",
                            f"shot_{shot}", f"threshold_{threshold:.2f}")
    
    predictions_csv = os.path.join(base_dir, "predictions.csv")
    if not os.path.exists(predictions_csv):
        return {}
    
    try:
        df = pd.read_csv(predictions_csv)
        pred_mapping = pd.Series(df['predicted_class'].values, index=df['image_filename']).to_dict()
        return pred_mapping
    except Exception as e:
        print(f"  [!] ì˜¤ë¥˜: {e}")
        return {}

def normalize_class_name(class_name):
    """í´ë˜ìŠ¤ëª… ì •ê·œí™”"""
    if class_name is None or not isinstance(class_name, str):
        return None
    return "Unknown" if "unknown" in class_name.lower() else class_name

# --- ë¶„ì„ í•¨ìˆ˜ ---

def analyze_fsl_vs_groundtruth(gt_mapping, fsl_mapping):
    """FSL vs Ground Truth ì§ì ‘ ëŒ€ì¡° ë¶„ì„"""
    
    # ë§¤ì¹­ë˜ëŠ” íŒŒì¼ë“¤ë§Œ ë¶„ì„
    common_files = set(gt_mapping.keys()) & set(fsl_mapping.keys())
    
    analysis = {
        'total_files': len(common_files),
        'gt_distribution': Counter(),
        'fsl_distribution': Counter(),
        'confusion_matrix': defaultdict(lambda: defaultdict(int)),
        'gt_class_performance': defaultdict(lambda: defaultdict(int)),
        'accuracy_by_gt_class': {},
        'overall_accuracy': 0
    }
    
    correct_predictions = 0
    
    for filename in common_files:
        gt_raw = gt_mapping[filename]
        fsl_raw = fsl_mapping[filename]
        
        gt_class = normalize_class_name(gt_raw)
        fsl_class = normalize_class_name(fsl_raw)
        
        # í†µê³„ ìˆ˜ì§‘
        analysis['gt_distribution'][gt_class] += 1
        analysis['fsl_distribution'][fsl_class] += 1
        analysis['confusion_matrix'][gt_class][fsl_class] += 1
        
        # Ground Truth í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
        if gt_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
            analysis['gt_class_performance'][gt_class]['total'] += 1
            
            if gt_class == fsl_class:
                analysis['gt_class_performance'][gt_class]['correct'] += 1
                correct_predictions += 1
            elif fsl_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
                analysis['gt_class_performance'][gt_class]['wrong_class'] += 1
            elif fsl_class == "Unknown":
                analysis['gt_class_performance'][gt_class]['predicted_unknown'] += 1
        elif gt_class == "Unknown":
            if fsl_class == "Unknown":
                correct_predictions += 1
    
    # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°
    for gt_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
        perf = analysis['gt_class_performance'][gt_class]
        if perf['total'] > 0:
            analysis['accuracy_by_gt_class'][gt_class] = perf['correct'] / perf['total']
        else:
            analysis['accuracy_by_gt_class'][gt_class] = 0.0
    
    # ì „ì²´ ì •í™•ë„
    analysis['overall_accuracy'] = correct_predictions / len(common_files) if common_files else 0.0
    
    return analysis

def create_table8_style_analysis(gt_mapping, fsl_mapping):
    """Table 8 ìŠ¤íƒ€ì¼ ë¶„ì„: GT í´ë˜ìŠ¤ë³„ FSL ì˜ˆì¸¡ ë¶„í¬"""
    
    common_files = set(gt_mapping.keys()) & set(fsl_mapping.keys())
    
    # GT í´ë˜ìŠ¤ë³„ë¡œ FSLì´ ì–´ë–»ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€ ë¶„ì„
    gt_class_analysis = defaultdict(lambda: defaultdict(int))
    
    for filename in common_files:
        gt_raw = gt_mapping[filename]
        fsl_raw = fsl_mapping[filename]
        
        gt_class = normalize_class_name(gt_raw)
        fsl_class = normalize_class_name(fsl_raw)
        
        if gt_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
            if fsl_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
                gt_class_analysis[gt_class]['within_target'] += 1
            elif fsl_class == "Unknown":
                gt_class_analysis[gt_class]['marked_as_others'] += 1
    
    return gt_class_analysis

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("Few-Shot Learning vs Ground Truth ì§ì ‘ ëŒ€ì¡° ë¶„ì„")
    print("=" * 60)
    
    experiments = get_available_experiments()
    gt_mapping = get_ground_truth_mapping()
    
    if not experiments or not gt_mapping:
        print("ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“Š ë¶„ì„ ì‹œì‘: {len(experiments)}ê°œ ì‹¤í—˜ ì¡°í•© ì²˜ë¦¬")
    
    all_results = []
    table8_results = []
    
    for i, (shot, threshold) in enumerate(experiments, 1):
        print(f"\n[{i:2d}/{len(experiments)}] Shot={shot}, Threshold={threshold:.2f} ë¶„ì„ ì¤‘...")
        
        fsl_mapping = get_fsl_predictions(shot, threshold)
        if not fsl_mapping:
            print("  âš ï¸  FSL ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        # ì§ì ‘ ëŒ€ì¡° ë¶„ì„
        analysis = analyze_fsl_vs_groundtruth(gt_mapping, fsl_mapping)
        
        # ì „ì²´ ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
        result_row = {
            'Shot': shot,
            'Threshold': threshold,
            'Total_Files': analysis['total_files'],
            'Overall_Accuracy': analysis['overall_accuracy'],
            'FSL_Class_0': analysis['fsl_distribution'].get('Class_0', 0),
            'FSL_Class_1': analysis['fsl_distribution'].get('Class_1', 0),
            'FSL_Class_2': analysis['fsl_distribution'].get('Class_2', 0),
            'FSL_Class_3': analysis['fsl_distribution'].get('Class_3', 0),
            'FSL_Unknown': analysis['fsl_distribution'].get('Unknown', 0),
            'FSL_Target_Total': (analysis['fsl_distribution'].get('Class_0', 0) + 
                               analysis['fsl_distribution'].get('Class_1', 0) + 
                               analysis['fsl_distribution'].get('Class_2', 0) + 
                               analysis['fsl_distribution'].get('Class_3', 0))
        }
        
        # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì¶”ê°€
        for gt_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
            result_row[f'Accuracy_{gt_class}'] = analysis['accuracy_by_gt_class'][gt_class]
        
        all_results.append(result_row)
        
        # Table 8 ìŠ¤íƒ€ì¼ ë¶„ì„
        table8_analysis = create_table8_style_analysis(gt_mapping, fsl_mapping)
        
        true_class_map = {
            "Class_0": "Fence (C1)", "Class_1": "Sidewalk (C2)", 
            "Class_2": "Parked car (C3)", "Class_3": "Traffic cone (C4)"
        }
        
        for gt_class in ["Class_0", "Class_1", "Class_2", "Class_3"]:
            within = table8_analysis[gt_class]['within_target']
            others = table8_analysis[gt_class]['marked_as_others']
            
            table8_row = {
                'Shot': shot,
                'Threshold': threshold,
                'GT_Class': gt_class,
                'True_Class': true_class_map[gt_class],
                'Within_Target_Classes': within,
                'Manually_Marked_As_Others': others,
                'Total': within + others
            }
            table8_results.append(table8_row)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        fsl_target_total = result_row['FSL_Target_Total']
        print(f"  âœ… ì™„ë£Œ - ì „ì²´ ì •í™•ë„: {analysis['overall_accuracy']:.3f}, FSL íƒ€ê²Ÿ ì˜ˆì¸¡: {fsl_target_total}ê°œ")
    
    # ê²°ê³¼ ì €ì¥
    print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘...")
    
    if all_results:
        df_main = pd.DataFrame(all_results)
        main_path = os.path.join(PROJECT_ROOT, "fsl_vs_groundtruth_analysis.csv")
        df_main.to_csv(main_path, index=False)
        print(f"âœ… ë©”ì¸ ë¶„ì„ ê²°ê³¼ ì €ì¥: {main_path}")
        print(f"   ğŸ“ˆ ì´ {len(df_main)} í–‰")
        
        # Thresholdë³„ FSL Target Total ê°ì†Œ íŒ¨í„´ í™•ì¸
        print("\n--- Thresholdë³„ FSL Target Total ë³€í™” (Shot=1 ì˜ˆì‹œ) ---")
        shot1_data = df_main[df_main['Shot'] == 1].sort_values('Threshold')
        for _, row in shot1_data.iterrows():
            print(f"Threshold {row['Threshold']:.2f}: {int(row['FSL_Target_Total']):5d}ê°œ (ì •í™•ë„: {row['Overall_Accuracy']:.3f})")
    
    if table8_results:
        df_table8 = pd.DataFrame(table8_results)
        table8_path = os.path.join(PROJECT_ROOT, "fsl_vs_groundtruth_table8.csv")
        df_table8.to_csv(table8_path, index=False)
        print(f"\nâœ… Table 8 ìŠ¤íƒ€ì¼ ë¶„ì„ ì €ì¥: {table8_path}")
        print(f"   ğŸ“ˆ ì´ {len(df_table8)} í–‰")
        
        # Table 8 Total ê°ì†Œ íŒ¨í„´ í™•ì¸
        print("\n--- Table 8 Total í•©ê³„ ë³€í™” (Shot=1 ì˜ˆì‹œ) ---")
        shot1_table8 = df_table8[df_table8['Shot'] == 1].groupby('Threshold')['Total'].sum().sort_index()
        for threshold, total in shot1_table8.items():
            print(f"Threshold {threshold:.2f}: {int(total):5d}ê°œ")
    
    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"ğŸ“Š ì²˜ë¦¬ëœ ì‹¤í—˜ ì¡°í•©: {len(all_results)}ê°œ")
    print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"   - fsl_vs_groundtruth_analysis.csv (ì „ì²´ ì„±ëŠ¥ ë¶„ì„)")
    print(f"   - fsl_vs_groundtruth_table8.csv (GT í´ë˜ìŠ¤ë³„ FSL ì˜ˆì¸¡ ë¶„í¬)")

if __name__ == "__main__":
    main() 