#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë™ì¼ ë°ì´í„°ì…‹ ê¸°ì¤€ AutoDistill vs Few-Shot Learning ì„±ëŠ¥ ë¹„êµ
"""

import os
import json
import pandas as pd
import numpy as np
from collections import defaultdict, Counter
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.metrics import precision_recall_fscore_support

def get_ground_truth_mapping():
    """Ground Truth ë§¤í•‘ ìƒì„±"""
    print("=== Ground Truth ë§¤í•‘ ìƒì„± ===")
    
    gt_dir = "data/test_category/7.results/ground_truth"
    gt_mapping = {}
    gt_stats = Counter()
    
    class_folders = ["Class_0", "Class_1", "Class_2", "Class_3", 
                    "unknown_egifence", "unknown_human", "unknown_none", "unknown_road"]
    
    for class_folder in class_folders:
        class_path = os.path.join(gt_dir, class_folder)
        if os.path.exists(class_path):
            files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            for filename in files:
                gt_mapping[filename] = class_folder
                gt_stats[class_folder] += 1
            print(f"  {class_folder}: {len(files)}ê°œ")
    
    print(f"Ground Truth ì´ íŒŒì¼ ìˆ˜: {len(gt_mapping)}")
    return gt_mapping, gt_stats

def get_autodistill_predictions():
    """AutoDistill ë² ì´ìŠ¤ë¼ì¸ ì˜ˆì¸¡ ê²°ê³¼ ë§¤í•‘ ìƒì„±"""
    print("\n=== AutoDistill ë² ì´ìŠ¤ë¼ì¸ ì˜ˆì¸¡ ê²°ê³¼ ===")
    
    # 6.preprocessed ë””ë ‰í† ë¦¬ì—ì„œ AutoDistill ë¶„ë¥˜ ê²°ê³¼ ìˆ˜ì§‘
    preprocessed_dir = "data/test_category/6.preprocessed"
    autodistill_mapping = {}
    autodistill_stats = Counter()
    
    class_folders = ["Class_0", "Class_1", "Class_2", "Class_3", 
                    "unknown_egifence", "unknown_human", "unknown_none", "unknown_road"]
    
    for class_folder in class_folders:
        class_path = os.path.join(preprocessed_dir, class_folder)
        if os.path.exists(class_path):
            files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            for filename in files:
                autodistill_mapping[filename] = class_folder
                autodistill_stats[class_folder] += 1
            print(f"  {class_folder}: {len(files)}ê°œ")
    
    print(f"AutoDistill ì´ íŒŒì¼ ìˆ˜: {len(autodistill_mapping)}")
    return autodistill_mapping, autodistill_stats

def get_few_shot_predictions(shot=1, threshold=0.5):
    """Few-Shot Learning ì˜ˆì¸¡ ê²°ê³¼ ë§¤í•‘ ìƒì„±"""
    print(f"\n=== Few-Shot Learning ì˜ˆì¸¡ ê²°ê³¼ (Shot: {shot}, Threshold: {threshold}) ===")
    
    few_shot_dir = f"data/test_category/7.results/resnet/shot_{shot}/threshold_{threshold:.2f}"
    few_shot_mapping = {}
    few_shot_stats = Counter()
    
    if os.path.exists(few_shot_dir):
        for item in os.listdir(few_shot_dir):
            item_path = os.path.join(few_shot_dir, item)
            if os.path.isdir(item_path) and item not in ["annotations_by_class", "comparison"]:
                files = [f for f in os.listdir(item_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
                for filename in files:
                    few_shot_mapping[filename] = item
                    few_shot_stats[item] += 1
                print(f"  {item}: {len(files)}ê°œ")
    
    print(f"Few-Shot ì´ íŒŒì¼ ìˆ˜: {len(few_shot_mapping)}")
    return few_shot_mapping, few_shot_stats

def normalize_class_names(class_name):
    """í´ë˜ìŠ¤ëª… ì •ê·œí™”"""
    if class_name == "Unknown":
        return "Unknown"
    elif class_name.startswith("Class_"):
        return class_name
    elif class_name.startswith("unknown_"):
        return "Unknown"
    else:
        return class_name

def create_comparison_data(gt_mapping, autodistill_mapping, few_shot_mapping):
    """ë¹„êµ ë°ì´í„° ìƒì„±"""
    print("\n=== ë¹„êµ ë°ì´í„° ìƒì„± ===")
    
    # ê³µí†µ íŒŒì¼ë“¤ë§Œ ì‚¬ìš©
    common_files = set(gt_mapping.keys()) & set(autodistill_mapping.keys()) & set(few_shot_mapping.keys())
    print(f"ê³µí†µ íŒŒì¼ ìˆ˜: {len(common_files)}")
    
    comparison_data = []
    
    for filename in common_files:
        gt_class = gt_mapping[filename]
        autodistill_class = autodistill_mapping[filename]
        few_shot_class = few_shot_mapping[filename]
        
        # í´ë˜ìŠ¤ëª… ì •ê·œí™”
        gt_normalized = normalize_class_names(gt_class)
        autodistill_normalized = normalize_class_names(autodistill_class)
        few_shot_normalized = normalize_class_names(few_shot_class)
        
        comparison_data.append({
            'filename': filename,
            'ground_truth': gt_normalized,
            'autodistill_pred': autodistill_normalized,
            'few_shot_pred': few_shot_normalized,
            'autodistill_correct': gt_normalized == autodistill_normalized,
            'few_shot_correct': gt_normalized == few_shot_normalized
        })
    
    return pd.DataFrame(comparison_data)

def calculate_performance_metrics(df):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    print("\n=== ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ===")
    
    # ì „ì²´ ì •í™•ë„
    autodistill_accuracy = df['autodistill_correct'].mean()
    few_shot_accuracy = df['few_shot_correct'].mean()
    
    print(f"AutoDistill ì •í™•ë„: {autodistill_accuracy:.4f} ({autodistill_accuracy*100:.2f}%)")
    print(f"Few-Shot ì •í™•ë„: {few_shot_accuracy:.4f} ({few_shot_accuracy*100:.2f}%)")
    print(f"ì„±ëŠ¥ ê°œì„ : {few_shot_accuracy - autodistill_accuracy:.4f} ({(few_shot_accuracy - autodistill_accuracy)*100:.2f}%p)")
    
    # í´ë˜ìŠ¤ë³„ ì •í™•ë„
    print("\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:")
    for class_name in sorted(df['ground_truth'].unique()):
        class_df = df[df['ground_truth'] == class_name]
        auto_acc = class_df['autodistill_correct'].mean()
        fs_acc = class_df['few_shot_correct'].mean()
        print(f"  {class_name}: AutoDistill {auto_acc:.4f} vs Few-Shot {fs_acc:.4f} (ê°œì„ : {fs_acc-auto_acc:.4f})")
    
    return {
        'autodistill_accuracy': autodistill_accuracy,
        'few_shot_accuracy': few_shot_accuracy,
        'improvement': few_shot_accuracy - autodistill_accuracy
    }

def create_confusion_matrices(df):
    """Confusion Matrix ìƒì„±"""
    print("\n=== Confusion Matrix ìƒì„± ===")
    
    labels = sorted(df['ground_truth'].unique())
    
    # AutoDistill Confusion Matrix
    cm_auto = confusion_matrix(df['ground_truth'], df['autodistill_pred'], labels=labels)
    
    # Few-Shot Confusion Matrix  
    cm_fs = confusion_matrix(df['ground_truth'], df['few_shot_pred'], labels=labels)
    
    return cm_auto, cm_fs, labels

def save_results(df, metrics, cm_auto, cm_fs, labels):
    """ê²°ê³¼ ì €ì¥"""
    print("\n=== ê²°ê³¼ ì €ì¥ ===")
    
    # 1. ìƒì„¸ ë¹„êµ ë°ì´í„°
    df.to_csv("autodistill_vs_few_shot_comparison.csv", index=False)
    print("âœ“ autodistill_vs_few_shot_comparison.csv")
    
    # 2. ì„±ëŠ¥ ìš”ì•½
    summary = {
        "total_files": len(df),
        "autodistill_accuracy": metrics['autodistill_accuracy'],
        "few_shot_accuracy": metrics['few_shot_accuracy'], 
        "performance_improvement": metrics['improvement'],
        "confusion_matrix_autodistill": cm_auto.tolist(),
        "confusion_matrix_few_shot": cm_fs.tolist(),
        "class_labels": labels
    }
    
    with open("performance_comparison_summary.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    print("âœ“ performance_comparison_summary.json")
    
    # 3. Confusion Matrix CSV
    cm_auto_df = pd.DataFrame(cm_auto, index=labels, columns=labels)
    cm_fs_df = pd.DataFrame(cm_fs, index=labels, columns=labels)
    
    cm_auto_df.to_csv("autodistill_confusion_matrix.csv")
    cm_fs_df.to_csv("few_shot_confusion_matrix.csv")
    print("âœ“ confusion matrix CSV íŒŒì¼ë“¤")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("AutoDistill vs Few-Shot Learning ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
    print("=" * 60)
    
    # 1. Ground Truth ë§¤í•‘
    gt_mapping, gt_stats = get_ground_truth_mapping()
    
    # 2. AutoDistill ì˜ˆì¸¡ ê²°ê³¼
    autodistill_mapping, autodistill_stats = get_autodistill_predictions()
    
    # 3. Few-Shot Learning ì˜ˆì¸¡ ê²°ê³¼ (Shot 1, Threshold 0.5)
    few_shot_mapping, few_shot_stats = get_few_shot_predictions(shot=1, threshold=0.5)
    
    # 4. ë¹„êµ ë°ì´í„° ìƒì„±
    df = create_comparison_data(gt_mapping, autodistill_mapping, few_shot_mapping)
    
    # 5. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = calculate_performance_metrics(df)
    
    # 6. Confusion Matrix ìƒì„±
    cm_auto, cm_fs, labels = create_confusion_matrices(df)
    
    # 7. ê²°ê³¼ ì €ì¥
    save_results(df, metrics, cm_auto, cm_fs, labels)
    
    print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ì´ {len(df)}ê°œ íŒŒì¼ ë¶„ì„ë¨")
    
    return df, metrics

if __name__ == "__main__":
    df, metrics = main() 