최종 PRD: Autodistill 기반 고정확도/고효율 이미지 라벨링 및 분류 최적화 (v3.0 - Complete)
# Overview
본 프로젝트는 노동 집약적인 이미지/비디오 데이터 라벨링 과정에서 발생하는 시간 및 비용 문제를 해결하는 것을 목표로 합니다. 특히, 대규모 데이터셋에 대한 100%에 가까운 정확도의 라벨링은 고품질 비전 AI 모델 학습의 핵심 전제 조건이나, 수동 작업은 비효율적입니다. 프로젝트의 핵심은 LLM(Florence-2)과 SAM2(Segment Anything Model 2)를 결합한 Autodistill 기술을 활용하여, 대상 객체에 대한 box 및 mask 정보를 신속하게 선제적으로 수집하고, 이를 기반으로 각 클래스에 대한 annotation 정보를 전처리하는 것입니다. Autodistill의 초기 정확도는 낮을 수 있으나, 본 프로젝트는 이를 기반으로 **4가지 이미지 분류 방법론(Cosine Similarity, Cosine Similarity + Feedback Loop, VLM, VLM + Feedback Loop)**을 비교 평가하여, 비전 모델 학습에 사용될 수 있는 최고 수준의 정확도와 효율성을 가진 이미지 분류 및 정제 방법을 찾는 것을 궁극적인 목표로 합니다.
이 솔루션은 데이터 라벨링 팀, AI 연구원, 그리고 빠르고 정확한 학습 데이터셋 구축이 필요한 모든 개발자를 대상으로 하며, 라벨링 시간과 비용을 획기적으로 절감하고, 고품질 비전 AI 모델 개발을 가속화하는 데 기여할 것입니다. 모든 과정은 부분적으로 MCP(Model Control Panel, 가칭)를 통해 사용자 친화적으로 제어되며, 특히 Google Gemini 2.5 Pro API의 무료 이점을 적극 활용하여 Feedback Loop 및 VLM 평가에 적용될 예정입니다. 프로젝트의 모든 결과(정확도, 소요 시간, 개선 과정, 프롬프트 엔지니어링 등)는 상세히 기록 및 문서화되어 피드백 루프에 활용될 수 있는 구조로 관리됩니다.
# Core Features
Autodistill 기반 자동 객체 정보 수집 및 전처리 모듈 (Florence-2 + SAM2)
What it does:
사용자가 정의한 caption ontology (label: caption 형식)와 원본 이미지를 입력받습니다.
Florence-2 모델(base, large, base-ft, large-ft 중 선택 가능)이 이미지를 임베딩하고, caption ontology의 텍스트를 임베딩하여 텍스트 기반으로 이미지에서 대상 객체의 box 정보를 추출합니다.
추출된 box 정보를 SAM2 모델(sam2hiera{tiny, small, base_plus, large}, sam2.1_hiera{tiny, small, base_plus, large} 중 선택 가능)의 box prompt로 사용하여 객체의 mask 정보를 생성합니다.
생성된 box 및 mask 좌표값은 각각 Florence-2 및 SAM2가 정의하는 형식으로 .txt 및 .json 파일로 저장됩니다 (폴더: 3.box, 4.mask).
저장된 box 및 mask 좌표값을 이용하여 원본 이미지를 전처리합니다. 전처리 과정은 다음과 같습니다:
원본 이미지에서 box 좌표만큼 이미지를 크롭(crop)합니다.
크롭된 이미지에서 mask 좌표 영역을 제외한 나머지 배경 영역을 검은색으로 처리합니다.
객체의 비율을 유지한 채로 지정된 크기(예: 224x224)로 리사이즈합니다.
전처리된 이미지는 5.preprocessed-img 폴더에 저장됩니다.
전처리된 이미지는 배경이 검은색이고 객체의 mask 정보만 나타나는 형태가 될 수 있음을 인지하고 후속 처리 모듈에서 이를 고려합니다.
Why it's important: 수동 라벨링의 초기 단계를 자동화하여 시간과 노력을 대폭 절감하며, 후속 분류 및 정제 작업의 일관된 기반 데이터를 제공합니다. 다양한 모델 선택 옵션을 제공하여 유연성을 높입니다.
How it works at a high level: Florence-2의 텍스트-이미지 매칭 능력으로 객체 후보를 찾고, SAM2의 정교한 분할 능력으로 마스크를 생성하여, 이를 바탕으로 표준화된 입력 이미지를 만듭니다.
고려 사항: Autodistill 관련 Python 패키지(grounded sam2, florence-2, autodistill 등) 내부 로직 및 데이터 처리 방식에 대한 면밀한 분석과 필요시 안정적인 연동을 위한 코드 수정/랩핑(wrapping)이 필요합니다. 패키지 버전 변경에 따른 호환성 문제도 주의해야 합니다.
카테고리 기반 유연한 데이터 관리 시스템
What it does: 모든 데이터(원본 이미지, support set, box/mask 좌표, 전처리 이미지, 분류 결과 등)는 사용자가 정의하는 "카테고리"별로 폴더 구조 내에서 관리됩니다. 사용자는 MCP를 통해 카테고리를 쉽게 전환하고, 각 카테고리에 맞는 원본 이미지 폴더(1.input)와 support set 폴더(2.support-set)를 유연하게 지정할 수 있습니다.
Why it's important: 대용량 데이터를 다룰 때 스토리지 관리의 효율성을 높이고, 다양한 프로젝트나 실험 간의 데이터 분리 및 재사용을 용이하게 합니다.
How it works at a high level: 메인 프로젝트 루트 (/home/ml/project-agi) 하위에 카테고리명으로 폴더를 생성하고, 그 안에 표준화된 하위 폴더들(1.input, 2.support-set 등)을 배치합니다. MCP는 현재 활성 카테고리를 인지하고 관련 경로를 동적으로 설정합니다.
방법 1: Autodistill + Cosine Similarity 기반 이미지 분류
What it does: 2.support-set 폴더에 제공된 예시 이미지(support set, 사용자가 제공하는 초기 Ground Truth 역할)와 5.preprocessed-img 폴더의 전처리된 이미지들 간의 Cosine Similarity를 계산하여 가장 유사한 클래스로 분류합니다. caption ontology와 support-set의 클래스 순서는 일치해야 합니다.
Why it's important: 간단하고 빠르게 구현 가능한 이미지 유사도 기반 분류 방법의 성능을 평가하고, 초기 베이스라인 정확도를 확보합니다.
How it works at a high level: Support set 이미지와 전처리된 이미지에서 각각 특징 벡터를 추출합니다. 추출된 특징 벡터들 간의 코사인 유사도를 계산하고, 가장 높은 유사도를 가진 support set 이미지의 클래스로 해당 전처리 이미지를 분류합니다.
Support Set 활용 전략: Support set 이미지 개수(K-shot: 1, 5, 10, 30 등 MCP에서 선택 가능) 및 유사도 임계값(threshold, MCP에서 설정 가능)을 파라미터로 설정하여 실험합니다.
특징 추출기:
선정 목표: 다양한 이미지(단순, 복잡, 객체 일부만 보이는 경우, 배경 제거된 전처리 이미지 등)에 강인하고, 특히 mask 정보만 남은 전처리 이미지의 형태적/의미론적 특징을 잘 포착할 수 있는 모델을 선정합니다.
후보 및 전략:
CLIP (Contrastive Language-Image Pre-training): 이미지와 텍스트를 동일 공간에 임베딩하므로, caption ontology의 텍스트 정보와 전처리 이미지의 시각적 특징을 함께 고려 가능. 전처리된 이미지의 형태적 특징과 더불어 "이것은 [클래스명]의 모습이다"라는 의미론적 유사도까지 포착할 가능성.
DINOv2 (Self-Distillation with No Labels v2): 레이블 없이 학습되어 다양한 시각적 특징에 강인하며, 특히 객체의 세부적인 형태와 질감에 대한 표현력이 우수할 수 있어 mask 기반 이미지에 적합할 수 있음.
(보조) ResNet-50: 과거 경험 기반으로 비교군으로 활용.
선정 방식: 위 후보들을 대상으로 초기 실험을 진행하고, Ground Truth (support set) 기반 평가 및 실제 다양한 전처리 이미지에 대한 임베딩 분포를 분석하여 최종 모델을 선정하거나, 상황에 따라 조합/선택하는 전략을 MCP에서 제공합니다.
방법 2: Autodistill + Cosine Similarity + Feedback Loop 기반 이미지 분류
What it does: 방법 1의 분류 결과에 대해 MCP를 통해 사용자 피드백(예: support set 수정, 분류 결과 수정, 애매하거나 이상한 이미지 제외 처리)을 받아, 이를 반영하여 Cosine Similarity 분류 로직(예: support set 업데이트, 특징 공간 가중치 조정, 임베딩 집계 방식 변경)을 개선하고 재분류를 수행하는 반복적인 프로세스입니다.
Why it's important: 초기 분류 오류를 점진적으로 수정하고 모델의 암묵적인 학습을 유도하여 정확도를 지속적으로 향상시킵니다. Ground Truth를 활용하여 개선 방향을 명확히 하고, 사용자의 직관을 시스템에 반영합니다.
How it works at a high level: 사용자가 MCP를 통해 피드백을 입력하면, 시스템은 이를 해석하여 support set을 업데이트하거나, 특징 추출/비교 로직에 영향을 주는 파라미터를 조정합니다. 이후 변경된 설정을 바탕으로 재분류를 실행합니다.
Feedback Loop 로직 (Cosine Similarity):
사용자 피드백(예: 오분류 이미지 지정 - "A 이미지는 실제로는 X 클래스이다", support set 이미지 추가/제외, "이 이미지는 어떤 클래스에도 속하지 않거나 판별 불가"로 플래그 지정)을 MCP를 통해 수집합니다.
임베딩 전략 관여: Support set 이미지 추가 시, 전체 support set 이미지들의 임베딩 벡터를 평균내어 대표 벡터로 사용할지, 또는 각 support set 이미지 임베딩과의 개별 유사도 중 최대/평균을 사용할지 등 임베딩 집계 방식을 MCP에서 선택 가능하도록 하고, 피드백에 따라 이 전략을 변경할 수 있도록 합니다. (예: 특정 클래스의 support set이 다양해지면 평균보다 k-NN 방식이 유리할 수 있음).
애매하거나 이상한 이미지 처리: 사용자가 MCP를 통해 "판별 불가" 또는 "노이즈"로 지정한 이미지는 다음 분류 대상에서 제외하거나, 별도의 "미분류" 클래스로 처리하여 다른 클래스에 영향을 주지 않도록 합니다. Box가 너무 작거나 mask가 부정확하더라도 실제 객체가 보이는 경우를 위해, 단순 크기/정확도 필터링보다는 사용자 판단을 우선합니다. 이 제외된 이미지 목록과 이유는 기록되어 추후 분석에 활용됩니다.
파라미터 버전 관리: 피드백으로 인해 변경된 파라미터(K-shot 값, 유사도 임계값, support set 구성, 임베딩 집계 방식 등)는 새로운 "실험 버전"으로 관리됩니다. MCP는 특정 실험 버전에 해당하는 파라미터 세트를 불러와 적용할 수 있도록 지원하여 이전 실험 결과의 재현성을 보장합니다.
방법 3: Autodistill + VLM (Florence-2) 기반 이미지 분류
What it does: 5.preprocessed-img 폴더의 전처리된 이미지들을 Florence-2 VLM 기능을 이용하여 caption ontology에 정의된 클래스로 직접 분류합니다.
Why it's important: 최신 VLM의 강력한 이미지 이해 및 제로샷/퓨샷 분류 능력을 활용하여 높은 정확도를 달성하고자 합니다.
How it works at a high level: 전처리된 이미지를 Florence-2 VLM에 입력으로 제공하고, caption ontology의 각 "label: caption"을 참조하여 가장 적합한 클래스로 분류하도록 프롬프팅합니다.
방법 4: Autodistill + VLM + Feedback Loop 기반 이미지 분류
What it does: 방법 3의 분류 결과에 대해 MCP를 통해 사용자 피드백을 받아, 이를 반영하여 VLM의 프롬프트나 분류 전략을 개선하고 재분류를 수행하는 반복적인 프로세스입니다. Gemini 2.5 Pro API (무료)가 피드백 처리 및 프롬프트 개선 LLM으로 활용됩니다.
Why it's important: VLM의 잠재적 오류를 수정하고 모델 성능을 지속적으로 최적화하며, 특히 Ground Truth를 활용하여 명확한 개선을 유도하고, 정답을 모르는 데이터에 대한 탐색적 개선을 시도합니다.
How it works at a high level: 사용자가 MCP를 통해 피드백을 입력하면, (Gemini 2.5 Pro 등의) LLM이 이 피드백을 분석하여 Florence-2 VLM에 전달할 프롬프트를 수정하거나, 분류 결정에 영향을 미치는 다른 파라미터를 조정합니다. 이후 변경된 설정을 바탕으로 재분류를 실행합니다.
Feedback Loop 로직 (VLM - Gemini 2.5 Pro 활용):
입력 데이터 정리 (Gemini용):
사용자 피드백: MCP를 통해 수집된 구조화된 피드백 (예: {"image_id": "img_001.png", "feedback_type": "relabel", "previous_vlm_class": "cat", "corrected_class": "dog", "user_reason": "귀 모양과 꼬리가 개의 특징임"} 또는 {"image_id": "img_002.png", "feedback_type": "flag_noise", "user_reason": "객체가 불분명함"}).
관련 이미지 정보: 피드백 대상 이미지의 경로 또는 Base64 인코딩된 데이터, (필요시) 해당 이미지의 Autodistill box/mask 정보.
현재 VLM 프롬프트: 현재 Florence-2 VLM에 사용 중인 프롬프트 템플릿.
Caption Ontology: 현재 사용 중인 클래스 정의.
(선택적) 이전 사이클의 주요 통계: 특정 클래스 간 혼동이 잦았던 정보 등.
Gemini 역할 (프롬프트 엔지니어링):
피드백 분석 및 이해: 제공된 피드백의 의도와 내용을 파악.
개선 전략 수립:
오분류 수정: "이 이미지는 [이전 클래스]가 아니라 [새 클래스]로 분류되어야 합니다. 그 이유는 [사용자 이유]입니다. 다음 분류 시 이 점을 고려하여 [새 클래스]의 특징(예: [캡션 온톨로지 내용] 또는 [사용자가 언급한 특징])에 더 주목해주세요." 와 같은 구체적인 지시사항을 포함하는 프롬프트를 Florence-2용으로 생성.
애매한 이미지 처리: "이 이미지는 사용자에 의해 노이즈로 판별되었습니다. 다음 분류 시 유사한 특징을 가진 이미지는 낮은 신뢰도를 부여하거나 '미분류'로 처리해주세요." 와 같은 가이드라인 생성.
caption ontology 수정 제안: 만약 피드백이 특정 클래스 정의의 모호성을 시사한다면, Gemini가 해당 caption ontology의 caption을 더 명확하게 수정하거나 예시를 추가하는 방안을 제안 (MCP를 통해 사용자에게 제시 후 확정).
Florence-2용 프롬프트 생성/수정: 분석 결과를 바탕으로 기존 프롬프트를 수정하거나, 상황에 맞는 새로운 프롬프트를 생성.
caption ontology 수정의 영향 및 파라미터 버전 관리: caption ontology 수정은 Autodistill의 객체 탐지 결과 자체를 변경시키므로, 이는 전체 파이프라인 재실행을 의미할 수 있습니다. 피드백 루프에서 caption ontology 수정이 제안될 경우, 그 파급 효과(예: 전체 annotation 수 변화)를 신중히 고려하고, 사용자에게 변경 범위를 명확히 인지시킨 후 적용해야 합니다. "절대적인 annotation 수 증가"가 반드시 성공적인 피드백을 의미하지 않을 수 있음을 인지합니다. (예: 노이즈 증가). 변경된 파라미터는 새로운 "실험 버전"으로 관리됩니다.
종합 결과 분석, 보고 및 피드백 시스템 연동
What it does:
4가지 방법론 각각에 대해 분류 정확도(TP, TN, FP, FN 기반의 Balanced Accuracy, Macro F1-score, Fall-out, MCC 등, 클래스 불균형 고려 옵션 포함), 분류 소요 시간, 피드백 루프 단계별 개선 과정, 프롬프트 엔지니어링 진화 과정 등을 상세히 기록하고 비교 분석합니다.
모든 분류 결과는 원본 Autodistill 결과 대비 어느 클래스에서 어떻게 이동했는지 추적 가능해야 하며, Confusion Matrix(binary, multi-class)를 통해 시각화됩니다.
Confusion Matrix의 raw output (TP, TN, FP, FN 값)은 피드백 루프에 활용 가능한 형태로 저장됩니다.
모든 결과는 문서화되며, 이 문서는 다시 피드백 루프의 입력으로 사용될 수 있는 구조(예: LLM이 분석하여 개선 방향 제안)를 가집니다.
전처리된 이미지에 대한 메타데이터는 각 분류 방식에 따라 annotation 정보를 재구성하여 저장함으로써, 각 단계별(Autodistill 정확도, 4가지 분류 방식 정확도, 이를 통해 학습된 YOLO 모델 평가) 평가가 가능하도록 합니다.
Ground Truth 활용 및 사이클별 변화 추적: 초기 Support Set을 Ground Truth의 일부로 간주하고, 각 피드백 사이클을 거치면서 특정 이미지(예: 사이클 1에서 오분류되었던 이미지 A)의 분류 결과가 Ground Truth에 얼마나 근접하게 변하는지 추적하고 기록합니다.
군집화 변화 분석: 각 사이클 후 동일 클래스로 분류된 이미지들이 특징 공간(선택된 특징 추출기 기반)에서 얼마나 더 밀집되거나 잘 분리되는지 시각화 및 정량적 지표(예: 실루엣 계수)로 평가합니다.
Why it's important: 각 방법론의 장단점을 명확히 파악하고, 데이터 특성 및 목표에 가장 적합한, "최고성능과 최고효율"을 나타내는 이미지 분류 방법을 최종적으로 선정하며, 지속적인 개선을 위한 데이터 기반 의사결정을 지원합니다. 정보 손실 없는 상세한 기록은 재현성 및 심층 분석을 보장합니다.
How it works at a high level: 각 방법론 실행 후 생성되는 로그, 분류 결과 파일, Confusion Matrix 데이터 등을 통합하여 표준화된 리포트를 생성합니다. 이 리포트는 MCP를 통해 조회 가능하며, 특정 데이터는 다음 피드백 사이클의 입력으로 자동/수동 연동됩니다.
데이터 저장 형식 (대시보드 및 시각화 고려):
실험 결과 및 로그: Apache Parquet 형식을 기본으로 사용. 컬럼 기반 저장으로 분석 쿼리 성능이 우수하고, Pandas 및 Spark와 호환성이 좋으며, 압축률도 높아 대용량 데이터에 적합.
MCP용 실시간/갱신형 대시보드 데이터: Parquet 파일을 주기적으로 읽어와 메모리 내 캐시(예: Redis) 또는 경량 DB(예: SQLite)에 요약/집계 데이터를 저장하여 대시보드에 빠르게 제공. 또는 Streamlit/Dash와 같은 도구가 Parquet 파일을 직접 읽어 갱신형 대시보드를 구성할 수 있도록 지원.
이미지 메타데이터 및 피드백: JSON Lines 또는 MongoDB와 같은 문서 지향 DB를 고려하여 유연한 스키마와 복잡한 중첩 데이터 저장 지원.
모니터링을 위한 포괄적 데이터 로깅: 피드백 루프의 효과를 정확히 판단하기 위해, 각 사이클/실험 버전별로 모든 입력 파라미터, 중간 산출물 경로, 사용된 모델 버전, 생성된 로그, 사용자 피드백 내용, 시스템 환경 정보 등을 빠짐없이 기록합니다. 이 기록은 다음 피드백 루프에 직접/간접적으로 반영됩니다.
# User Experience (MCP 중심)
User Personas:
AI 연구원/개발자: 새로운 라벨링 및 분류 방법론을 실험, 평가, 최적화하는 주 사용자.
데이터 관리자: 대규모 데이터셋의 카테고리별 관리 및 전처리 파이프라인 운영 담당.
Key User Flows (MCP를 통해 수행):
프로젝트/카테고리 설정:
새 카테고리 생성 또는 기존 카테고리 선택.
해당 카테고리의 1.input 및 2.support-set 폴더 경로 지정.
caption ontology (label: caption 목록) 입력/수정.
Autodistill용 Florence-2 및 SAM2 모델 버전 선택.
Autodistill 실행 및 전처리:
설정된 내용으로 Autodistill 실행 명령.
3.box, 4.mask, 5.preprocessed-img 생성 결과 확인.
분류 방법론 실행 및 파라미터 조정:
4가지 방법론 중 하나 이상 선택하여 실행.
(방법 1, 2) 특징 추출기 모델 및 임베딩 집계 방식 선택, K-shot 값, 유사도 임계값 설정.
(방법 2, 4) Feedback Loop 관련 설정 (LLM 모델 선택 등 - Gemini 2.5 Pro 기본).
결과 확인 및 분석:
각 방법론별 분류 정확도, Confusion Matrix, 소요 시간 등 리포트 조회.
분류된 이미지 샘플 확인.
Feedback Loop 수행 (방법 2, 4):
분류 결과에 대한 피드백 입력 (예: 특정 이미지의 클래스 수정, 새로운 support image 추가/삭제, caption ontology 수정, 애매하거나 이상한 이미지 플래깅).
피드백 기반 재분류 실행.
YOLO 학습용 데이터셋 생성:
정제된 annotation 정보를 YOLO 형식으로 변환하여 출력.
정확도 문제점 기록 및 종합 평가 (MCP 연동):
각 처리 과정(Autodistill, 분류 방법론 1-4)의 결과물(이미지, 좌표, 분류 결과 등)을 MCP에서 확인.
사용자는 MCP를 통해 특정 이미지나 결과에 대해 표준화된 문제 유형을 선택하고, 추가적인 설명(텍스트, 숫자 등)을 기록할 수 있음.
이러한 기록들은 종합되어 "종합 평가" 대시보드 형태로 제공되며, 이를 바탕으로 사용자는 다음 피드백 루프를 위한 파라미터 조정이나 프로젝트 방향 수정을 결정.
오분류 이미지 선택 및 특징 기록: 피드백 루프 과정에서 사용자가 MCP를 통해 잘못 분류된 이미지를 직접 선택하고, 해당 이미지의 시각적 특징이나 오분류 원인에 대한 코멘트를 남기면, 이 정보가 구조화되어 다음 루프의 LLM(Gemini) 분석 입력으로 활용됨.
애매하거나 이상한 이미지 플래깅: 사용자는 MCP의 이미지 뷰어에서 특정 이미지를 "판별 불가/노이즈", "배경만 있음", "Box/Mask 부정확하나 객체는 보임" 등의 표준화된 태그로 지정하고, 이 정보는 해당 이미지의 메타데이터로 저장되어 피드백 루프 및 최종 분석에 활용됨.
실험 버전 관리 및 파라미터 세트 로드/저장: MCP에서 피드백 루프나 수동 변경으로 인해 달라진 모든 관련 파라미터(Autodistill 모델 버전, K-shot, 임계값, 특징 추출기 모델, 임베딩 집계 방식, VLM 프롬프트 템플릿 등)를 포함하는 "실험 버전" 스냅샷을 저장하고, 특정 버전을 선택하여 시스템 전체에 일관되게 설정을 불러와 적용할 수 있도록 지원.
대시보드 조회:
실시간/갱신형 대시보드: 현재 진행 중인 분류 작업의 요약 통계, 최근 피드백 반영 현황, 주요 성능 지표(Ground Truth 대비 정확도 변화, 군집화 지표 변화 등)를 시각적으로 확인.
사용자 신뢰도 점수 입력 (선택적 대규모 평가): 방대한 양의 이미지에 대해 모든 사용자가 신뢰도를 평가하기 어려우므로, MCP는 샘플링된 이미지 세트에 대해서만 신뢰도 평가를 요청하거나, 특정 "애매한" 이미지들에 대해서만 집중적으로 평가를 요청하는 기능을 제공. 이 결과는 대시보드에 집계되어 표시.
UI/UX Considerations (MCP):
웹 기반 인터페이스로 직관적이고 사용자 친화적인 경험 제공.
각 단계별 설정 및 실행 버튼 명확히 구분.
진행 상황 시각적 표시 (프로그레스 바, 로그 출력).
결과 리포트(표, 차트, 이미지 뷰어) 내장.
Support set 이미지 업로드/관리 기능.
caption ontology 편집기.
모든 설정값 저장 및 불러오기 기능 (실험 버전 관리와 연동).
# Technical Architecture
System Components:
MCP (Model Control Panel): 웹 프레임워크 (Python FastAPI/Flask + React/Vue.js 또는 Streamlit/Gradio) 기반 사용자 인터페이스 및 백엔드 API.
Autodistill 모듈:
Florence-2 (Hugging Face Transformers 라이브러리, 로컬 모델 파일).
SAM2 (Hugging Face Transformers 또는 공식 라이브러리, 로컬 모델 파일).
스크립트 위치: /home/ml/project-agi/scripts/autodistill_runner.py (가칭)
데이터 관리 모듈: 카테고리별 폴더 생성/관리, 파일 I/O 처리.
전처리 모듈: OpenCV, PIL 활용. (/home/ml/project-agi/scripts/preprocessor.py)
분류 모듈 (각 방법론별):
Cosine Similarity: Scikit-learn, 선택된 특징 추출기 (CLIP, DINOv2 등). (/home/ml/project-agi/scripts/classifier_cosine.py)
VLM (Florence-2): Florence-2 VLM 기능 직접 호출. (/home/ml/project-agi/scripts/classifier_vlm.py)
Feedback Loop 모듈:
피드백 데이터 저장소 (JSON Lines 또는 MongoDB).
피드백 해석 및 설정 변경 로직 (LLM - Gemini 2.5 Pro API 활용).
/home/ml/project-agi/scripts/feedback_handler.py
결과 분석 및 리포팅 모듈: Pandas, Matplotlib, Scikit-learn (metrics), HTML/Parquet 생성. (/home/ml/project-agi/scripts/reporter.py)
YOLO 데이터 변환 모듈: (/home/ml/project-agi/scripts/yolo_converter.py)
실험 버전 관리 모듈: 파라미터 스냅샷 저장/로드. (/home/ml/project-agi/scripts/version_control.py)
Data Models:
원본 이미지/비디오 데이터 (사용자 제공).
caption_ontology.json (카테고리별): {"label_id": 0, "label_name": "apple", "caption": "a red apple"}, ...
Box 좌표 파일 (.txt): [class_id_florence] x_center y_center width height (Florence-2 출력 형식 따름)
Mask 좌표 파일 (.json): SAM2 출력 형식 (세그멘테이션 폴리곤 또는 RLE)
전처리된 이미지 파일 (예: .png, .jpg).
분류 결과 파일 (classification_results_cycle_X.parquet): image_path, original_autodistill_class_id, method1_class_id, method1_score, ..., ground_truth_class_id (있을 경우), experiment_version_id
피드백 데이터 파일 (JSON Lines 또는 MongoDB 컬렉션): {"image_id": "xyz.png", "feedback_type": "relabel", "old_class_id": 0, "new_class_id": 1, "user_comment": "...", "timestamp": "...", "experiment_version_id_source": "..."}
Confusion Matrix raw data (confusion_matrix_raw_cycle_X.parquet): class_id, TP, TN, FP, FN, experiment_version_id
정확도 문제점 기록 데이터 (problem_log.parquet 또는 MongoDB 컬렉션): timestamp, category_id, image_id, process_stage, problem_type_code, user_description, system_generated_metrics_json, user_severity_rating, feedback_cycle_id, experiment_version_id
실험 버전 관리 데이터 (experiment_versions.json 또는 경량 DB): version_id, timestamp, base_version_id, parameter_snapshot_json, description, associated_feedback_ids
APIs and Integrations:
Google Gemini 2.5 Pro API (Feedback Loop, 프롬프트 엔지니어링 지원용).
(내부) MCP 백엔드 API - 프론트엔드와 통신.
Infrastructure Requirements:
Python 3.8+ 실행 환경.
GPU (NVIDIA, CUDA 지원) - Florence-2, SAM2, 딥러닝 기반 특징 추출기 실행 필수.
install_dependencies.sh (또는 requirements.txt)에 명시된 패키지.
충분한 스토리지 공간 (원본 데이터, 모델 파일, 생성된 데이터).
(권장) Docker 컨테이너 환경 (재현성 및 배포 용이성).
프로젝트 루트: /home/ml/project-agi
# Development Roadmap
Phase 1: Foundation & Core Autodistill Setup (MVP-1)
카테고리 기반 폴더 구조 설계 및 기본 I/O 유틸리티 개발.
MCP 기본 프레임워크 구축 (카테고리 설정, caption ontology 입력 UI).
Florence-2 모델 선택 및 box 추출 기능 구현 (스크립트화).
SAM2 모델 선택 및 box prompt 기반 mask 생성 기능 구현 (스크립트화).
Box/Mask 좌표 저장 로직 구현.
이미지 전처리 모듈 구현 (크롭, 마스크 적용, 리사이즈).
Autodistill 파이프라인 초기 실행 및 결과(전처리 이미지) 생성 확인.
정확도 문제점 기록 방식 정의 및 초기 구현: 표준화된 문제 유형 코드 정의, MCP에서의 기본 입력 인터페이스, 초기 저장 형식(JSON Lines 또는 Parquet) 구현.
실험 버전 관리 기본 개념 설계 및 수동 기록 방식 도입.
Phase 2: Baseline Classification & Initial Feedback Infrastructure (MVP-2)
특징 추출기 선정 및 구현 (Cosine Similarity용): CLIP, DINOv2 등 후보군 중 1차 선정 및 통합. K-shot (1, 5, 10, 30) 및 유사도 임계값 설정 UI (MCP), 임베딩 집계 방식 선택 UI (MCP).
방법 1 (Autodistill + Cosine Similarity) 분류기 구현 및 평가.
MCP에 Support Set 관리 기능 추가 (업로드, 클래스별 지정).
기본적인 결과 리포팅 기능 구현 (분류 결과 테이블, 간단한 정확도 지표).
Feedback Loop 기본 인프라 구축:
피드백 데이터 수집 인터페이스 프로토타입 (MCP 내, 오분류 수정, 애매한 이미지 플래깅 포함).
Gemini 2.5 Pro API 연동 (간단한 피드백 해석 및 로깅).
방법 2 (Cosine Similarity + Feedback Loop) 기초 기능 구현 (수동으로 support set 변경 후 재실행 수준).
실험 버전 관리 모듈 프로토타입 구현 (파라미터 스냅샷 저장/로드).
Phase 3: Advanced VLM Integration & Comprehensive Evaluation Framework
방법 3 (Autodistill + VLM - Florence-2) 분류기 구현 및 평가.
방법 4 (VLM + Feedback Loop) 기초 기능 구현 (Gemini 2.5 Pro 활용한 프롬프트 제안/수정).
종합 결과 분석 프레임워크 개발:
4가지 방법론 결과 통합 및 비교 로직.
Confusion Matrix 생성 및 시각화 (TP, TN, FP, FN raw data 저장 포함).
Balanced Accuracy, Macro F1-score 등 다양한 평가지표 계산.
Ground Truth 대비 변화 추적, 군집화 분석 기능.
YOLO 데이터셋 변환 기능 구현.
모든 결과 및 로그의 구조화된 문서화 시스템 설계 (Parquet 등 효율적 형식 적용).
Phase 4: Feedback Loop 고도화 및 MCP 완성
피드백 반영 로직 고도화 (Cosine Similarity & VLM): Gemini 2.5 Pro를 활용하여 사용자 피드백(오분류 이미지 특징 기록, 애매한 이미지 플래그 포함), Confusion Matrix 결과, 문제점 로그 등을 종합 분석하여 구체적인 설정 변경(support set 자동 제안, 특징 가중치 미세조정, VLM 프롬프트 동적 생성, 임베딩 집계 방식 추천 등)을 수행하는 자동화된 로직 개발.
Groundtruth를 모르는 경우의 Feedback Loop 전략 구체화 및 적용 (일관성, 군집화, 사용자 신뢰도, LLM 상대 평가 지표 활용).
MCP 기능 완성: 사용자 경험 개선, 상세 로그 뷰어, 고급 분석 기능, 대시보드(실시간/갱신형), 사용자 신뢰도 점수 입력 인터페이스(샘플링 기반), 실험 버전 관리 UI/UX 완성.
최종 보고서 자동 생성 기능.
Future Enhancements:
다양한 LLM/VLM 모델 추가 지원.
능동적 학습(Active Learning) 기법 도입.
실시간 협업 라벨링 기능 (MCP 확장).
# Logical Dependency Chain
환경 설정 및 기본 I/O (Foundation): Python 환경, GPU 드라이버, 필수 라이브러리 설치. 카테고리 기반 폴더 관리 로직. 실험 버전 관리 기본 설계.
Autodistill 파이프라인 구축 (Core Engine): Florence-2 연동 -> SAM2 연동 -> 좌표 저장 -> 이미지 전처리 순으로 개발. MCP에서 모델 선택 및 실행 제어.
Cosine Similarity 분류 (Baseline): 특징 추출기 구현/통합 -> Support Set 관리 -> Cosine Similarity 계산 및 분류. (Autodistill 결과 필요)
VLM 분류 (Alternative Baseline): Florence-2 VLM 기능 활용 분류. (Autodistill 결과 필요)
결과 분석 프레임워크 (Evaluation Core): 각 분류 결과 취합, 평가지표 계산, Confusion Matrix 생성, Ground Truth 변화 추적, 군집화 분석. (각 분류 방법론 결과 필요)
Feedback Loop 인프라 (Iteration Core): 피드백 수집 (MCP) -> 피드백 처리 (Gemini API) -> 설정 반영. 실험 버전 관리 모듈 연동. (각 분류 방법론 및 결과 분석 프레임워크 필요)
Feedback Loop 적용 (방법 2, 4): 각 분류 방법에 Feedback Loop 인프라 통합.
MCP 기능 확장 (Usability): 각 모듈 개발과 병행하여 MCP에 관련 UI/UX 지속적으로 추가. 대시보드, 문제점 기록, 실험 버전 관리 인터페이스 등.
YOLO 변환 및 최종 보고 (Output): 모든 정제 및 분석 완료 후 최종 산출물 생성.
# Risks and Mitigations
Technical Challenges:
Autodistill 정확도 변동성: 선택된 Florence-2/SAM2 모델 및 caption ontology 품질에 따른 초기 정확도 변동.
Mitigation: 다양한 모델 조합 테스트, caption ontology 작성 가이드라인 제공, Feedback Loop를 통한 점진적 개선.
특징 추출기 성능: 선택된 특징 추출기가 다양한 이미지 및 전처리된 mask 이미지에 대해 일관된 고성능을 보이지 않을 수 있음.
Mitigation: 여러 후보군(CLIP, DINOv2 등)에 대한 철저한 실험 및 비교 평가 후 최적 모델 선정 또는 조합 전략 사용. MCP에서 선택 옵션 제공.
Feedback Loop 로직 복잡성 및 예측 불가능성: 사용자 피드백을 효과적으로 해석하고 시스템 설정에 반영하는 로직 개발의 어려움. 피드백으로 인한 변경이 항상 긍정적인 결과를 보장하지 않음. 특히 caption ontology 변경은 파급 효과가 큼.
Mitigation: Gemini 2.5 Pro의 강력한 언어 이해 능력 활용, 단계적 기능 구현 (초기: 간단한 규칙 기반 -> 점차 LLM 기반 지능형으로), 충분한 테스트. 변경 전 시뮬레이션 또는 소규모 데이터 테스트, 변경 사항에 대한 명확한 롤백(Rollback) 메커니즘 (실험 버전 관리 활용), 사용자에게 변경 영향 범위 명시.
Groundtruth 부재 시 평가의 어려움 (일부 해결): 초기 Support Set을 Ground Truth로 활용하나, 대규모 미지의 데이터에 대한 평가는 여전히 간접적일 수 있음.
Mitigation: 일관성, 군집화, 사용자 신뢰도, LLM 상대 평가 등 다각적 지표 활용. 샘플링 기반 수동 검증 병행.
패키지 의존성 및 안정성: Autodistill 관련 외부 패키지의 업데이트나 내부 로직 변경으로 인한 예기치 않은 동작.
Mitigation: 특정 안정 버전의 패키지 고정 사용, 주요 기능에 대한 자체 테스트 코드 작성, 패키지 변경 로그 주시.
Resource Constraints:
GPU 자원: 다수 모델 동시 실행 및 대규모 데이터 처리 시 GPU 메모리 및 연산 시간 부족.
Mitigation: 효율적인 모델 사용, 배치 처리, 코드 최적화, 필요시 클라우드 GPU 활용.
API 비용 (Gemini 외): 다른 유료 API 사용 시 비용 관리.
Mitigation: Gemini 2.5 Pro 최대한 활용, API 호출 최소화 로직, 비용 모니터링.
Scope Creep:
MCP 기능 과다: 사용자 편의를 위한 MCP 기능이 계속 추가되어 개발 범위 확장.
Mitigation: 단계별 MVP 정의, 핵심 기능 우선 개발, 추가 기능은 우선순위화.
데이터 의존성:
Support Set 품질: Cosine Similarity 방법은 Support Set의 품질에 크게 의존.
Mitigation: MCP를 통한 쉬운 Support Set 관리 및 업데이트 기능 제공, Feedback Loop를 통한 Support Set 개선 유도.
# Appendix
Florence-2 모델 정보: (Hugging Face 링크, 논문 링크)
SAM2 모델 정보: (Hugging Face 링크, 논문 링크)
CLIP 모델 정보: (Hugging Face 링크, 논문 링크)
DINOv2 모델 정보: (Hugging Face 링크, 논문 링크)
Gemini 2.5 Pro API 문서 링크.
install_dependencies.sh / requirements.txt (초안)
초기 caption_ontology.json 예시.
참고 논문 및 자료: (Cosine Similarity 분류, VLM 기반 분류, Feedback Loop 관련 연구, 특징 추출기 관련 연구)
표준화된 문제 유형 코드 정의서 (초안).